
#NORMALITY TESTS IN ECONOMETRICS USING R  
##Author: R J Neel  
###Referene: Ben Lambert Econometrics Course, Introductory Econometrics: A modern approach by J Wooldrige, Econometric Analysis by W. Greene
    
Let us consider an example from the **wage1** dataset. Here, we test the relationship between wage and education and experience.
```{r,echo=FALSE,message=FALSE}
#To test the relation between education, experience and wage
library(wooldridge)
library(ggplot2)
library(gridExtra)
library(dplyr)
data=wage1

head(data)

#Regression function Wage= f(education, experience)

p1=ggplot(data, aes(x=educ,y=wage))+geom_point(col="orange")+ggtitle("Wage vs Education")+xlab("Education")+ylab("Wage")+geom_smooth(method='lm',se=0)
p2=ggplot(data, aes(x=exper,y=wage))+geom_point(col="red")+ggtitle("Wage vs Experience")+xlab("Experience")+ylab("Wage")+geom_smooth(method='lm',se = 0)

grid.arrange(p1,p2,ncol=2)

```
  
We devise the following model:  
wage=f(education, experience)

Therefore, we devise the following model:  
$Wage=\beta_0 + \beta_1*Education +\beta_2*Experience$
  
The result of regression is   
```{r,echo=FALSE, messages=FALSE}
fit=lm(wage~educ+exper,data)
fit
summary(fit)
anova(fit)
a=fit$coefficients[1] %>% round(2)
b1=fit$coefficients[2] %>% round(2)
b2=fit$coefficients[3] %>% round(2)
```
  
Thus, we have $Wage=`r a`+`r b1`*Education +`r b2`*Experience$
  
  
Now, we test for **NORMALITY**  

Let us see the distribution of wages  
```{r,echo=FALSE, message=FALSE}
ggplot(data, aes(x=wage))+geom_histogram(col="red",fill='orange')+ggtitle("Distribution of Wage")+xlab("Wage")+ylab("Frequency")
```
  
Prima facie it looks like the distribution is **skewed** towards the right.
  
Let us conduct all the normality tests  
  
**[1]Visual Tests**  
```{r,echo=FALSE, messages=FALSE}
library(ggpubr)
# Density plot
p3=ggdensity(data$wage, fill = "orange")+ggtitle('Density plot for wages')
# QQ plot
p4=ggqqplot(data$wage,col='orange')+ggtitle('QQ plot for wages') 
grid.arrange(p3,p4,ncol=2)
```  
    
**[2]Jarque-Berra Test**  
```{r,echo=FALSE, messages=FALSE}
library(tseries)
library(normtest)
jarque.bera.test(data$wage)
```  
  
**INTERPRETATION**  
For Jarque-Berra test our     
*Ho: Distribution is NORMAL*  
*Ha: Otherwise*  
A p value of $<0.05$ implies That the test stastic lies in the <span style="color: red;">REJECTION REGION</span>. Therefore, We **fail** to conclude that the distribution is **NORMAL**. It was already hinted in the Visual tests.  
    
**[3]Shapiro-Wilk Test**  
```{r,echo=FALSE, messages=FALSE}
shapiro.test(data$wage)
```  
  
As is in the case for Jarque-Berra test, In Shapiro-Wilkins test too = our       
*Ho: Distribution is NORMAL*  
*Ha: Otherwise*  
A p value of $<0.05$ implies That the test stastic lies in the <span style="color: red;">REJECTION REGION</span>. Therefore, We **fail** to conclude that the distribution is **NORMAL**. It was already hinted in the Visual tests.  

Shapiro-wilk is the more preferred test.  
    
**Let us now repeat the exercise with Log(wages)**    
Let us see the distribution of Log(wages)  
```{r,echo=FALSE, message=FALSE}
ggplot(data, aes(x=log(wage)))+geom_histogram(col="red",fill='orange')+ggtitle("Distribution of Ln(Wage)")+xlab("Ln(wage)")+ylab("Frequency")
```
  
Prima facie it does **NOT** look **NORMAL**
  
Let us conduct all the normality tests  
  
**[1]Visual Tests**  
```{r,echo=FALSE, messages=FALSE}
# Density plot
p5=ggdensity(log(data$wage), fill = "orange")+ggtitle('Density plot for wages')
# QQ plot
p6=ggqqplot(log(data$wage),col='orange')+ggtitle('QQ plot for wages') 
grid.arrange(p5,p6,ncol=2)
```  
    
**[2]Jarque-Berra Test**  
```{r,echo=FALSE, messages=FALSE}
library(tseries)
library(normtest)
jarque.bera.test(log(data$wage))
```  
  
**INTERPRETATION**  
The p value has increased but it is still $<0.05$ implies That the test stastic lies in the <span style="color: red;">REJECTION REGION</span>. Therefore, We **fail** to conclude that the distribution is **NORMAL**. It was already hinted in the Visual tests.  
    
**[3]Shapiro-Wilk Test**  
```{r,echo=FALSE, messages=FALSE}
shapiro.test(log(data$wage))
```  
  
As is in the case for Jarque-Berra test, In Shapiro-Wilkins test too it fails to prove **NORMALITY**



