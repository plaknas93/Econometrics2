---
output:
  html_document: default
  pdf_document: default
---
#**Chapter 2: Simple Linear Regression**

##*Author: J Wooldridge*


###**Regression Practice**

```{r,echo=FALSE}
library(wooldridge)
library(plyr)
library(dplyr)
library(ggplot2)
library(rsq) #For R sq
library(kableExtra) #For Table Graphics
library(broom)
library(cowplot)
```

#**Exapmple 2.3 CEO Salary and Return on Equity**
```{r, echo=FALSE}
summary(ceosal1$salary)
summary(ceosal1$roe)

fit1=lm(salary~roe,ceosal1)
summary(fit1)

sal_roe_plot=ggplot(ceosal1,aes(x=roe,y=salary))+geom_smooth(method='lm',se=FALSE,col='dark green')+geom_point(col='green')+ggtitle("Scatterplot: CEO Salary vs ROE")+annotate("text", x=55, y=14500, label = "R^2 == 0.01", parse=T)+annotate("text", x=55, y=13000, label = "hat(alpha) == 963.2", parse=T)+annotate("text", x=55, y=11500, label = "hat(beta) == 18.5", parse=T)+theme_bw()
sal_roe_plot
```
  
**Interpretation: **  
If the ROE of the the firm increases by 1 percentage point than the CEO's salary increasese by **`r (round(fit1$coefficients[2],2))`** thousand dollars.
  
#**Exapmple 2.4 Wage and Education**
  
Consider the scatterplot of wage vs education from the wage dataset and the OLS model estimates
```{r,echo=FALSE}
#OLS
fit=lm(wage~educ,wage1)
summary(fit)
fit
#Scatterplot+Regression line
wage_edu_plot=ggplot(wage1,aes(x=educ,y=wage))+geom_point(col='cornflower blue')+ggtitle("Scatterplot: Wage vs Education")+geom_smooth(method='lm',se=FALSE,col='red')+annotate("text", x=2, y=24, label = "R^2 == 0.16", parse=T)+annotate("text", x=2, y=22, label = "hat(alpha) == -0.90", parse=T)+annotate("text", x=2, y=20, label = "hat(beta) == 0.54", parse=T)+theme_bw()
wage_edu_plot
```
  
**Interpretation: **
1 more year of education  increases wage by a half a dollar per hour. <span style="color: red;">NOTE</span>: The <span style="color: red;">intercept</span> value of <span style="color: red;">-.54</span> implies negative hourly wage for no education. This is absurd. A person who has no education will not be paying his employer for doing work.

#**Exapmple 2.5 Voting Outcomes and Campaign Expenditures**
  
Consider the scatterplot of wage vs education from the wage dataset and the OLS model estimates
```{r,echo=FALSE}
#OLS
head(vote1)
fit2=lm(voteA~shareA,vote1)
summary(fit2)
fit2
#Scatterplot+Regression line
vote_share_plot=ggplot(vote1,aes(x=shareA,y=voteA))+geom_point(col='salmon')+ggtitle("Scatterplot: Voting Outcomes vs Campaign Expenditure")+geom_smooth(method='lm',se=FALSE,col='red')+annotate("text", x=95, y=40, label = "R^2 == 0.85", parse=T)+annotate("text", x=95, y=35, label = "hat(alpha) == 26.81", parse=T)+annotate("text", x=95, y=30, label = "hat(beta) == 0.46", parse=T)+theme_bw()
vote_share_plot
```
    
**Interpretation: **
Vote share increases by almost half a percent if Cadidate A increases his campaign spending by 1 percent in the total campaign spending among both. 


#**Example 2.6 CEO Salary and ROE**
```{r,echo=FALSE}
#OLS

data=ceosal1

data2= data %>% select(roe,salary)%>%mutate(pred_salary=round(fitted.values(fit1),2),residual=round(fit1$residuals,2))



cov_r_roe=cov(data2$roe,data2$residual)
m_pred=mean(data2$pred_salary)
m_pred
m_sal=mean(data2$salary)
m_sal

summary(fit1)
cor_pred_sal_act_sal=round(cor(data2$pred_salary,data2$salary),2)
cor_pred_sal_act_sal^2

ggplot(data2,aes(residual))+geom_histogram(binwidth=250,fill='cornflower blue',col='black')+ggtitle("Histogram of residuals")+xlab('residuals')+theme_bw()+annotate("text",x=11000,y=46,label="Covariance(residual,roe)== 0",parse=T)+annotate("text",x=11000,y=41,label="Mean_Actaul_Salary==1281.12",parse=T)+annotate("text",x=11000,y=36,label="Mean_Fitted_Salary== 1281.12",parse=T)

```
  
#**Example 2.7 Wage and Education**   
No Analysis required
  
#**Example 2.8 CEO Salary and ROE**  
The correlation between predicted salary and observed salary is **`r cor_pred_sal_act_sal`**. This when squared yields **`r round(cor_pred_sal_act_sal^2,2)`**.
  
The results of regression of salary on roe are:  
```{r,echo=FALSE} 
summary(fit1)
```
  
This explains the plot
```{r,echo=FALSE} sal_roe_plot```
  
#**Example 2.9 Voting Outcomes and Campaign Expenditures**   
The regresssion outcome as indicated by the plot, cleary, seems to be a better fit for the model.
<span style='color:red;'> But, How much better?</span>
```{r,echo=FALSE}
vote_share_plot
```
  
We check the R-Square also called the, Coefficient of Determination. In this case the R square value is **`r  rsq(fit2)`**.
  
#**2-4 Units of Measurement and Functional Form (Page 36)**    
##**(a) CHANGING UNITS OF MEASUREMENT**    
(1)Change in DEPENDENT VARIABLE UNIT  
Consider the case of CEO_Sal regressed on ROE. Here, CEO_Sal is interms of thousands of $ and ROE is measured as percentage. If CEO_Sal is instead changed to 100s, what would the impact on beta and alpha?

The new regression result is as follows:
```{r, echo=FALSE}
head(ceosal1)
data3= ceosal1 %>% select(salary,roe) %>% mutate(sal_100=salary*10) #Salary in 100 dollars
head(data3)

fit3=lm(sal_100~roe,data3)
fit3$coefficients
```
The old regression (CEO_sal on ROE) result was
```{r,echo=FALSE}
fit1$coefficients
```
Notice, both intercept and slope get multiplied by **10**.  
**In General, for every multiplication or division by any constant 'c' to the DEPENDENT variable must be repeated across all intercept and independent variable.**

(2)Change in INDEPENDENT VARIABLE UNIT  
Consider the case of CEO_Sal regressed on ROE. Here, CEO_Sal is interms of thousands of $ and ROE is measured as percentage. If ROE is instead changed to its decimal form, what would the impact on beta and alpha?

The new regression result is as follows:
```{r, echo=FALSE}
head(ceosal1)
data4= ceosal1 %>% select(salary,roe) %>% mutate(roe_dec=roe/100) #roe in decimal
head(data4)

fit4=lm(salary~roe_dec,data4)
fit4$coefficients
```
The old regression (CEO_sal on ROE) result was
```{r,echo=FALSE}
fit1$coefficients
```
Notice, only beta changes and alpha remains unchanged. ROE is multiplied by 100 for a division of 100 of the independent's units. 

**In General, every multiplication or division by any constant 'c' to the INDEPENDENT variable must be repeated with division or multiplication resp of across DEPENDENT ONLY**

##**(a) INCORPORATING NON LINEARITIES IN SR**  
(1)Level-Level model    
$y= \alpha + \beta x$ 
$\Delta x$ of 1 unit results in a $\beta$ units change in $x$.

(2)Log-Level model  
$y= \exp^{\alpha+\beta x}$  
In log form this would be written as
$\log (y)= \alpha+\beta x$
  
     
#**Example 2.10 A Log Wage Equation**  
For the log form of wage1 dataset,  
```{r, echo=FALSE}
fit5=lm(log(wage)~educ,wage1)
summary(fit5)
kable(tidy(fit5),digits = 3) %>% kable_styling(bootstrap_options = "striped", full_width = F)
```
Thus,  
**$\hat{\log (wage)}=0.584+.083 educ$**   
**$R^2=`r round(rsq(fit5),2)`$**    
**$n=`r nrow(wage1)`$**
  
**INTERPRETATION**  
The coefficient on educ has a percentage interpretation when it is multiplied by $100$: $\hat{wage}$ increases by $8.3\%$ for every additional year of education. This is what economists mean when they refer to the *“return to another year of education.”* (Page 38). 
  
For sake of completion let us compare the two regression outputs of by comparing the fitted values in each case.
```{r, echo=F}
d1=data.frame(educ=wage1$educ,pred_wage=round(fitted(fit),2))
plot_d1=ggplot(d1,aes(x=educ,y=pred_wage))+geom_line(color="salmon")+ggtitle("Regression of wage($) on educ(yrs)")+annotate("text", x=7.5, y=7.5, label = "hat(wage) == -0.09+0.54*educ", parse=T)+annotate("text", x=7.5, y=6.5, label = "R^2 == 0.164", parse=T)+theme_bw()

d2=data.frame(educ=wage1$educ,pred_wage=exp(0.584+0.083*wage1$educ))
plot_d2=ggplot(d2,aes(x=educ,y=pred_wage))+geom_line(color='salmon')+ggtitle("Regression of Log(wage) on educ(yrs)")+annotate("text", x=9, y=6, label = "wage == e^(0.58+0.083*educ)", parse=T)+annotate("text", x=8.2, y=5.5, label = "R^2 == 0.185", parse=T)+theme_bw()

plot_grid(plot_d1,plot_d2)
```
  

(2)Log-log model  
$\log (y)= \alpha+\beta \log(x)$
  
#**Example 2.11 CEO and Firm Sales**

```{r, echo=FALSE}
fit6=lm(log(salary)~log(sales),ceosal1)
summary(fit6)
kable(tidy(fit6),digits = 3) %>% kable_styling(bootstrap_options = "striped", full_width = F)
```
Thus,  
**$\hat{\log (salary)}=4.822+.257 log(sales)$**   
**$R^2=`r round(rsq(fit6),2)`$**    
**$n=`r nrow(ceosal1)`$**
  
**INTERPRETATION**  
The coefficient of $log(sales)$ is the estimated elasticity of salary with respect to sales. It implies that a $1\%$ increase in firm sales increases CEO salary by about $0.257\%$ -the usual interpretation of an elasticity. (Page 39). 

**#2-5 Expected values and variance of the OLS Estimators

# Assumption: Zero Conditionality of Mean and Heteroskedasticity  
Let us consider the education vs wage. As education level increases wage is likely to go up. Thus, we take sample for the following education levels:
```{r,echo=F}
ed= 1:25
```
  
The wage levels are taken over 1000 samples. The first of these samples looks like 
```{r,echo=FALSE}
library(dplyr)
w1=round((rnorm(100,mean=.5,sd=2))^2,2) #Lower wage
w2= round((rnorm(100,mean=2.5,sd=1))^2,2) #Mid wage
w3= round((rnorm(100,mean=5,sd=.5))^2,2) #High wage

w=0
all_samples=0
m=0
my_sample_mean=0
my_sample_sd=0
for(i in 1:1000)
{
  w[1:10]=sample(w1,10)
  w[11:20]=sample(w2,10)
  w[21:25]=sample(w2,5)
  my_sample_mean[i]= mean(w) %>% round(2)
  my_sample_sd[i]=sd(w) %>% round(2)
  d=data.frame(ed,w)
  all_samples[i]=list(d)
}
#all_samples[1]
d1=ldply(all_samples[1], data.frame)
d1

```
  
This sample has a mean wage of **`r round(mean(d1$w),2)`** and std deviation of **`r sd(d1$w)%>% round(2)`**. 
  
The scatterplot looks like  
```{r,echo=FALSE}
ggplot(d1,aes(x=ed,y=w))+geom_point(col='red',size=2)+ggtitle("Wage ($ per hour) vs Education (yrs)")+xlab("education")+ylab("wage")+theme_bw()
```
    
Next we turn to the sample distribution of wage over the same education levels
```{r,echo=FALSE}
dd=ldply(all_samples, data.frame) #The population

s=data.frame(sample_no=1:1000,my_sample_mean,my_sample_sd)

ggplot(data=s,aes(x=my_sample_mean,y=..density..))+geom_density(col='red')+theme_bw()+ggtitle("Distribution of Sample Means (Sampling Distribution)")+xlab("Sample Means")

```
  
The mean of this sampling distibution is **`r mean(s$my_sample_mean) %>% round(2)`** and std deviation is **`r sd(s$my_sample_mean) %>% round(2)`**. 

**#COMPARISON ACROSS SAMPLE, SAMPLING DISTRIBUTION & POPULATION**

```{r,echo=FALSE}
p=c("Sample","Sampling distrbution","Population")
q=c(round(mean(d1$w),2),mean(s$my_sample_mean)%>% round(2),mean(dd$w)%>% round(2))
r=c(round(sd(d1$w),2),sd(s$my_sample_mean)%>% round(2),sd(dd$w)%>% round(2))
z=data.frame(p,q,r)
colnames(z)=c(" ","Mean","Standard deviation")

kable(z) %>% kable_styling(bootstrap_options = "striped",full_width = F)
```
  
**#REGRESSION ESTIMATES POPULATION & SAMPLE**
  
Regression for Population
```{r,echo=FALSE}
library(ggpubr)
mfit=lm(w~ed,dd)
summary(mfit)

ggplot(dd,aes(x=ed,y=w))+geom_point()+geom_smooth(method='lm',se=0)+xlab("Education")+ylab("Wage")+ggtitle("Regression of wage on education")+stat_regline_equation(label.x = 18, label.y = 26)
```

  
Regression for Sample
```{r,echo=FALSE}
sfit=lm(w~ed,d1)
summary(sfit)
sfit
ggplot(d1,aes(x=ed,y=w))+geom_point(col='red',size=2)+geom_smooth(method='lm',se=0)+stat_regline_equation(label.x = 18, label.y = 26)+xlab("Education")+ylab("Wage")+ggtitle("Regression of wage on education")
```
    
**Now we attempt to find $\hat{\beta}$ for all samples***  
```{r,echo=FALSE}

sam=0
h_b=0
for(i in 1:1000)
{
  sam=ldply(all_samples[i], data.frame)
  smfit=lm(w~ed,sam)
  h_b[i]=smfit$coefficients[2] %>% round(2)
}
h_b_d=data.frame(n=1:1000,h_b)
ggplot(data=h_b_d,aes(x=h_b,y=..density..))+geom_density(col='red')+theme_bw()+labs(title=expression("Distribution of"~widehat(beta) ))+xlab(expression(widehat(beta) ))

```
  
The expected value of all one thousand $\hat{\beta}$s is **`r mean(h_b) %>% round(2)`** and sd is **`r sd(h_b) %>% round(2)`**.  
  
```{r,echo=FALSE}
pp=c("Sample","Sampling distrbution","Population")
qq=c(sfit$coefficients[2] %>% round(2),mean(h_b) %>% round(2),mfit$coefficients[2]%>% round(2))
qq
rr=c(round(sd(d1$w),2),sd(s$my_sample_mean)%>% round(2),sd(dd$w)%>% round(2))
z=data.frame(pp,qq)
colnames(z)=c(" ","Mean")

kable(z) %>% kable_styling(bootstrap_options = "striped",full_width = F)
```
  

